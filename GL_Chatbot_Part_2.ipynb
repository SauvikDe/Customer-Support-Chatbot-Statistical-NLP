{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4441445e",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "# Project Solution: GL Chatbot - Part 2\n",
    "\n",
    "### Context: Great Learning is looking forward to design an automation which can interact with the user, understand the problem and display the resolution procedure [if found as a generic request] or redirect the request to an actual human support executive if the request is complex or not in itâ€™s database. This is to support Academic Support department of Great Learning.\n",
    "\n",
    "### Objective: Design a Python based interactive semi-rule based chatbot which can do the following:\n",
    "1. Start chat session with greetings and ask what the user is looking for.\n",
    "2. Accept dynamic text based questions from the user. Reply back with relevant answer from the designed corpus.\n",
    "3. End the chat session only if the user requests to end else ask what the user is looking for. Loop continues till the user asks to end it.\n",
    "    \n",
    "### Section 2: This module contains the implementation of chatbot using the model built in Section 1\n",
    "#### Input:\n",
    "- GL Bot.json containing a designed corpus with tags, patterns, responses\n",
    "- Model architecture and weigths (chatbotModel.json and chatbotModel.h5)\n",
    "\n",
    "#### Usage:\n",
    "- Please execute chat() function to start conversation with virtual agent.\n",
    "    \n",
    "***\n",
    "***\n",
    "*Prepared by: Sauvik De*\n",
    "\n",
    "*Date: September 4, 2021*\n",
    "\n",
    "</font>\n",
    "\n",
    "##### Reference: https://www.mygreatlearning.com/blog/basics-of-building-an-artificial-intelligence-chatbot\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1411b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, json\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a88e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model data\n",
    "with open('GL Bot.json') as f:\n",
    "    corpus = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12bb8779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and model\n",
    "json_file = open('chatbotModel.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "model.load_weights(\"chatbotModel.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e066a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data\n",
    "WORDS = []  #Tokens\n",
    "LABELS = [] #Identified tags or labels\n",
    "\n",
    "for intents in corpus['intents']:\n",
    "    for pattern in intents['patterns']:\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        WORDS.extend(w)  #Bag of Words\n",
    "\n",
    "    # Add the missing tag if any\n",
    "    if intents['tag'] not in LABELS:\n",
    "        LABELS.append(intents['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf8752d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "tag_dict = {\"J\": 'a', #nltk.corpus.wordnet.ADJ,\n",
    "            \"N\": 'n', #nltk.corpus.wordnet.NOUN,\n",
    "            \"V\": 'v', #nltk.corpus.wordnet.VERB,\n",
    "            \"R\": 'r'  #nltk.corpus.wordnet.ADV\n",
    "           }\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "   pTag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "   return tag_dict.get(pTag, 'n') \n",
    "\n",
    "WORDS = [lemmatizer.lemmatize(w, pos=get_wordnet_pos(w)).lower() for w in WORDS if w != '?']\n",
    "WORDS = sorted(list(set(WORDS))) #Fetch unique list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17a4dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_input(input_sent, W):\n",
    "    bow = []\n",
    "    for w in W:\n",
    "        if w in input_sent:\n",
    "            bow.append(1)\n",
    "        else: bow.append(0)\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80f86293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text chat utility function\n",
    "def chat():\n",
    "    import numpy as np\n",
    "    \n",
    "    print('Hello, my name is GLBOT\\nI am your virtual assistant.')\n",
    "    print('\\n***To quit, please type: QUIT')\n",
    "    print(\"***Not the response you are looking for? .. please type: *\")\n",
    "    \n",
    "    while True:\n",
    "        inputText = input('\\n\\nYou: ')\n",
    "        if inputText.lower()=='*':\n",
    "            print('GLBOT: Please rephrase your question and type again.')\n",
    "            continue\n",
    "        if inputText.lower()=='quit':\n",
    "            print('GLBOT: Good Bye!')\n",
    "            break\n",
    "        \n",
    "        results = model.predict([ohe_input(inputText.lower(), WORDS)])\n",
    "        results_index = np.argmax(results)\n",
    "        tag = LABELS[results_index]    \n",
    "        \n",
    "        for intent in corpus['intents']:\n",
    "            if intent['tag'] == tag:\n",
    "                responses = intent['responses']\n",
    "                print('GLBOT:', responses[0])\n",
    "        \n",
    "        #if tag == 'Exit':\n",
    "        #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "653afb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is GLBOT\n",
      "I am your virtual assistant.\n",
      "\n",
      "***To quit, please type: QUIT\n",
      "***Not the response you are looking for? .. please type: *\n",
      "\n",
      "\n",
      "You: hi need help pls\n",
      "GLBOT: Hello! how may I help you?\n",
      "\n",
      "\n",
      "You: what is machine learning\n",
      "GLBOT: Link: Machine Learning wiki \n",
      "\n",
      "\n",
      "You: deep learning concepts?\n",
      "GLBOT: Link: Neural Nets wiki\n",
      "\n",
      "\n",
      "You: what the hell!\n",
      "GLBOT: Please use respectful words\n",
      "\n",
      "\n",
      "You: *\n",
      "GLBOT: Please rephrase your question and type again.\n",
      "\n",
      "\n",
      "You: i think i am good for now, thanks\n",
      "GLBOT: I hope I was able to assist you. Please type in Quit to exit. Good Bye!\n",
      "\n",
      "\n",
      "You: quit\n",
      "GLBOT: Good Bye!\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
